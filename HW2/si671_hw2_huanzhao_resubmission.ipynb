{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc num is 960, sentence num is 14349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('./DataNer.txt', 'r') as fr:\n",
    "    res = []\n",
    "    sent_num = 0\n",
    "    doc_num = 0\n",
    "    last = '=='\n",
    "    for line in fr.readlines():\n",
    "        line = line.strip()\n",
    "        if line=='-DOCSTART- -X- O O':\n",
    "            doc_num += 1\n",
    "        if line=='' or line=='-DOCSTART- -X- O O':\n",
    "            if last=='' or last=='-DOCSTART- -X- O O':\n",
    "                pass\n",
    "            else:\n",
    "                sent_num+=1\n",
    "            last = line\n",
    "            continue\n",
    "        last = line\n",
    "        res.append([doc_num, sent_num]+line.split())\n",
    "    print('doc num is {}, sentence num is {}'.format(doc_num, sent_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(res, columns=['doc_num', 'sent_num', 'word', 'pos', 'chunking_tag', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunking_tag</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>further</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>scientific</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_num  sent_num        word  pos chunking_tag tag\n",
       "0        1         1          He  PRP         I-NP   O\n",
       "1        1         1        said  VBD         I-VP   O\n",
       "2        1         1     further   JJ         I-NP   O\n",
       "3        1         1  scientific   JJ         I-NP   O\n",
       "4        1         1       study   NN         I-NP   O"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207270, 6), (23825,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.shape, data_df.word.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-MISC</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>8454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-MISC</td>\n",
       "      <td>4642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>10214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-PER</td>\n",
       "      <td>11394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>O</td>\n",
       "      <td>172494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tag     cnt\n",
       "0   B-LOC      11\n",
       "1  B-MISC      37\n",
       "2   B-ORG      24\n",
       "3   I-LOC    8454\n",
       "4  I-MISC    4642\n",
       "5   I-ORG   10214\n",
       "6   I-PER   11394\n",
       "7       O  172494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupby('tag').size().reset_index(name='cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"</td>\n",
       "      <td>2225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>''</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(</td>\n",
       "      <td>2973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>)</td>\n",
       "      <td>2974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>,</td>\n",
       "      <td>7426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>.</td>\n",
       "      <td>7501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>:</td>\n",
       "      <td>2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC</td>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CD</td>\n",
       "      <td>20218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>13622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EX</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FW</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IN</td>\n",
       "      <td>19333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JJ</td>\n",
       "      <td>12015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>JJR</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JJS</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LS</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MD</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NN</td>\n",
       "      <td>24209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NNP</td>\n",
       "      <td>35159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NNPS</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NNS</td>\n",
       "      <td>10022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NN|SYM</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PDT</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POS</td>\n",
       "      <td>1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PRP</td>\n",
       "      <td>3246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PRP$</td>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RB</td>\n",
       "      <td>4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RBR</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>RBS</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RP</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SYM</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>TO</td>\n",
       "      <td>3504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UH</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VB</td>\n",
       "      <td>4345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>VBD</td>\n",
       "      <td>8398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>VBG</td>\n",
       "      <td>2630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>VBN</td>\n",
       "      <td>4139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>VBP</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>2457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>WDT</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>WP</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>WP$</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>WRB</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pos    cnt\n",
       "0        \"   2225\n",
       "1        $    430\n",
       "2       ''     37\n",
       "3        (   2973\n",
       "4        )   2974\n",
       "5        ,   7426\n",
       "6        .   7501\n",
       "7        :   2456\n",
       "8       CC   3713\n",
       "9       CD  20218\n",
       "10      DT  13622\n",
       "11      EX    137\n",
       "12      FW    166\n",
       "13      IN  19333\n",
       "14      JJ  12015\n",
       "15     JJR    382\n",
       "16     JJS    258\n",
       "17      LS     13\n",
       "18      MD   1214\n",
       "19      NN  24209\n",
       "20     NNP  35159\n",
       "21    NNPS    695\n",
       "22     NNS  10022\n",
       "23  NN|SYM      4\n",
       "24     PDT     33\n",
       "25     POS   1584\n",
       "26     PRP   3246\n",
       "27    PRP$   1553\n",
       "28      RB   4044\n",
       "29     RBR    164\n",
       "30     RBS     37\n",
       "31      RP    542\n",
       "32     SYM    458\n",
       "33      TO   3504\n",
       "34      UH     30\n",
       "35      VB   4345\n",
       "36     VBD   8398\n",
       "37     VBG   2630\n",
       "38     VBN   4139\n",
       "39     VBP   1461\n",
       "40     VBZ   2457\n",
       "41     WDT    510\n",
       "42      WP    536\n",
       "43     WP$     25\n",
       "44     WRB    392"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupby('pos').size().reset_index(name='cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunking_tag</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-ADJP</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-ADVP</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-NP</td>\n",
       "      <td>3841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-PP</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-SBAR</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-VP</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-ADJP</td>\n",
       "      <td>1395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-ADVP</td>\n",
       "      <td>2804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-CONJP</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-INTJ</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-LST</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-NP</td>\n",
       "      <td>122477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I-PP</td>\n",
       "      <td>18945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I-PRT</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I-SBAR</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I-VP</td>\n",
       "      <td>27102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>O</td>\n",
       "      <td>28234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunking_tag     cnt\n",
       "0        B-ADJP       2\n",
       "1        B-ADVP      22\n",
       "2          B-NP    3841\n",
       "3          B-PP     258\n",
       "4        B-SBAR       8\n",
       "5          B-VP     166\n",
       "6        I-ADJP    1395\n",
       "7        I-ADVP    2804\n",
       "8       I-CONJP      73\n",
       "9        I-INTJ      61\n",
       "10        I-LST      36\n",
       "11         I-NP  122477\n",
       "12         I-PP   18945\n",
       "13        I-PRT     541\n",
       "14       I-SBAR    1305\n",
       "15         I-VP   27102\n",
       "16            O   28234"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.groupby('chunking_tag').size().reset_index(name='cnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[['pos', 'chunking_tag']].drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From data exploration, we can see that:\n",
    "    - There are 960 docs with 1439 sentences\n",
    "    - There are 207270 rows, 6 columns and 23825 unique words\n",
    "    - By grouping the data by tag, we can see that there are 8 unique values for label and 'O' has the most amount\n",
    "    - By grouping the data by pos, we can see that there are 45 unique values for label and 'NNP' has the most amount\n",
    "    - By grouping the data by chunking_data, we can see that there are 17 unique values for label and 'I-NP' has the most amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using One-Hot Encoding to process data. Then split the data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2tag = data_df['tag'].unique()\n",
    "tag2idx = {v:k for k, v in enumerate(idx2tag)}\n",
    "# data_df['label'] = data_df['tag'].map(tag2idx)\n",
    "# One-hot Encode\n",
    "X_ml = pd.get_dummies(data_df[['word', 'pos', 'chunking_tag']])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ml.values, data_df['tag'].values, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fuc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the large data size after One-Hot Encoding, I would create funtions for incremental training. Here I use 10 folds to process the data for each model that I will be implementing in the following report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, flods=10):\n",
    "    n = len(X_train)\n",
    "    gap = n//flods\n",
    "    print('training sample num is {}'.format(n))\n",
    "    for i in range(1, flods):\n",
    "        print('flods num is {}'.format(i))\n",
    "        model.partial_fit(X_train[gap*(i-1):gap*i], y_train[gap*(i-1):gap*i], idx2tag)\n",
    "    model.partial_fit(X_train[gap*i:], y_train[gap*i:], idx2tag)\n",
    "    return model\n",
    "\n",
    "def partial_pred(model, X_test, flods=10):\n",
    "    n = len(X_test)\n",
    "    gap = n//flods\n",
    "    print('test sample num is {}'.format(n))\n",
    "    y_pred = np.array([])\n",
    "    for i in range(1, flods):\n",
    "        print('flods num is {}'.format(i))\n",
    "        p = model.predict(X_test[gap*(i-1):gap*i])\n",
    "        y_pred = np.append(y_pred, p)\n",
    "    p = model.predict(X_test[gap*i:])\n",
    "    y_pred = np.append(y_pred, p)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample num is 145089\n",
      "flods num is 1\n",
      "flods num is 2\n",
      "flods num is 3\n",
      "flods num is 4\n",
      "flods num is 5\n",
      "flods num is 6\n",
      "flods num is 7\n",
      "flods num is 8\n",
      "flods num is 9\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier(random_state=0)\n",
    "model = train_model(model, X_train, y_train, flods=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sample num is 62181\n",
      "flods num is 1\n",
      "flods num is 2\n",
      "flods num is 3\n",
      "flods num is 4\n",
      "flods num is 5\n",
      "flods num is 6\n",
      "flods num is 7\n",
      "flods num is 8\n",
      "flods num is 9\n"
     ]
    }
   ],
   "source": [
    "y_pred= partial_pred(model,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test sample num is :62181\n",
      "f1 score is :0.9189757278359705\n"
     ]
    }
   ],
   "source": [
    "result = f1_score(y_test, y_pred, average='weighted', labels=idx2tag)\n",
    "print('the test sample num is :{}'.format(len(y_test)))\n",
    "print('f1 score is :{}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.98      0.99      0.98     51703\n",
      "       I-ORG       0.90      0.48      0.63      3078\n",
      "       I-PER       0.97      0.42      0.58      3498\n",
      "      I-MISC       0.78      0.59      0.67      1381\n",
      "       I-LOC       0.39      0.88      0.54      2497\n",
      "       B-LOC       0.00      0.00      0.00         5\n",
      "      B-MISC       0.00      0.00      0.00        12\n",
      "       B-ORG       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.92     62181\n",
      "   macro avg       0.50      0.42      0.43     62181\n",
      "weighted avg       0.95      0.92      0.92     62181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = classification_report(y_pred=y_pred, y_true=y_test, labels=idx2tag)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied SGD Linear Classifier with 145089 train data and 62181 test data. The f1 score we got is 0.919, which is a decent number. But we need to compare it with following models in order to find the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Multinomial Naive Bayes Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample num is 145089\n",
      "flods num is 1\n",
      "flods num is 2\n",
      "flods num is 3\n",
      "flods num is 4\n",
      "flods num is 5\n",
      "flods num is 6\n",
      "flods num is 7\n",
      "flods num is 8\n",
      "flods num is 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=0.01)\n",
    "model = train_model(model, X_train, y_train, flods=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sample num is 62181\n",
      "flods num is 1\n",
      "flods num is 2\n",
      "flods num is 3\n",
      "flods num is 4\n",
      "flods num is 5\n",
      "flods num is 6\n",
      "flods num is 7\n",
      "flods num is 8\n",
      "flods num is 9\n"
     ]
    }
   ],
   "source": [
    "y_pred= partial_pred(model,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test sample num is :62181\n",
      "f1 score is :0.9572338661892663\n"
     ]
    }
   ],
   "source": [
    "result = f1_score(y_test, y_pred, average='weighted', labels=idx2tag)\n",
    "print('the test sample num is :{}'.format(len(y_test)))\n",
    "print('f1 score is :{}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.99      0.98      0.99     51703\n",
      "       I-ORG       0.83      0.71      0.76      3078\n",
      "       I-PER       0.79      0.96      0.87      3498\n",
      "      I-MISC       0.66      0.79      0.72      1381\n",
      "       I-LOC       0.85      0.82      0.84      2497\n",
      "       B-LOC       0.00      0.00      0.00         5\n",
      "      B-MISC       0.00      0.00      0.00        12\n",
      "       B-ORG       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.96     62181\n",
      "   macro avg       0.62      0.66      0.64     62181\n",
      "weighted avg       0.96      0.96      0.96     62181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = classification_report(y_pred=y_pred, y_true=y_test, labels=idx2tag)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied the Multinomial Naive Bayes Model Classifier with alpha = 0.01 and the f1 score is 0.957, which is higher than that of SGD Linear Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample num is 145089\n",
      "flods num is 1\n",
      "flods num is 2\n",
      "flods num is 3\n",
      "flods num is 4\n",
      "flods num is 5\n",
      "flods num is 6\n",
      "flods num is 7\n",
      "flods num is 8\n",
      "flods num is 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=8, n_iter_no_change=5, n_jobs=-1,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Perceptron( n_jobs=-1, max_iter=8)\n",
    "model = train_model(model, X_train, y_train, flods=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sample num is 62181\n",
      "flods num is 1\n",
      "flods num is 2\n",
      "flods num is 3\n",
      "flods num is 4\n",
      "flods num is 5\n",
      "flods num is 6\n",
      "flods num is 7\n",
      "flods num is 8\n",
      "flods num is 9\n"
     ]
    }
   ],
   "source": [
    "y_pred= partial_pred(model,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test sample num is :62181\n",
      "f1 score is :0.9421607695711566\n"
     ]
    }
   ],
   "source": [
    "result = f1_score(y_test, y_pred, average='weighted', labels=idx2tag)\n",
    "print('the test sample num is :{}'.format(len(y_test)))\n",
    "print('f1 score is :{}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.99      0.99      0.99     51703\n",
      "       I-ORG       0.88      0.52      0.65      3078\n",
      "       I-PER       0.96      0.68      0.80      3498\n",
      "      I-MISC       0.81      0.74      0.77      1381\n",
      "       I-LOC       0.49      0.92      0.64      2497\n",
      "       B-LOC       1.00      0.60      0.75         5\n",
      "      B-MISC       0.00      0.00      0.00        12\n",
      "       B-ORG       0.88      1.00      0.93         7\n",
      "\n",
      "    accuracy                           0.94     62181\n",
      "   macro avg       0.75      0.68      0.69     62181\n",
      "weighted avg       0.96      0.94      0.94     62181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = classification_report(y_pred=y_pred, y_true=y_test, labels=idx2tag)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I applied the Perceptron Classifier with n_jobs=-1, max_iter=8, and alpha = 0.0001. The f1 score is 0.942, still not as high as the Multinomial Naive Bayes Model Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Random Fields (CRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0, \n",
    "        'word.lower()': word.lower(), \n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['word'].values.tolist(), \n",
    "                                                   s['pos'].values.tolist(), \n",
    "                                                   s['tag'].values.tolist())]\n",
    "grouped = data_df.groupby('sent_num').apply(agg_func)\n",
    "sentences = [s for s in grouped]\n",
    "\n",
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is :0.9796403640122624\n"
     ]
    }
   ],
   "source": [
    "result = metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=idx2tag)\n",
    "print('f1 score is :{}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.99      1.00      0.99     52496\n",
      "       I-ORG       0.89      0.86      0.87      2935\n",
      "       I-PER       0.92      0.94      0.93      3404\n",
      "      I-MISC       0.92      0.83      0.87      1380\n",
      "       I-LOC       0.92      0.92      0.92      2480\n",
      "       B-LOC       1.00      0.50      0.67         4\n",
      "      B-MISC       0.00      0.00      0.00         6\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     62705\n",
      "   macro avg       0.71      0.63      0.66     62705\n",
      "weighted avg       0.98      0.98      0.98     62705\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = metrics.flat_classification_report(y_test, y_pred, labels = idx2tag)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the CRF model, I used word2features and grouped by sent_num. The f1 score is 0.980, which is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM-CRF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Input, Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers.crf import CRF\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch': [], 'epoch': []}\n",
    "        self.accuracy = {'batch': [], 'epoch': []}\n",
    "        self.val_loss = {'batch': [], 'epoch': []}\n",
    "        self.val_acc = {'batch': [], 'epoch': []}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        print(logs.keys())\n",
    "        print(logs.get('crf_viterbi_accuracy'))\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('crf_viterbi_accuracy'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_crf_viterbi_accuracy'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('crf_viterbi_accuracy'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_crf_viterbi_accuracy'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train crf_viterb_acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val crf_viterb_acc')\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('crf_viterb_acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()\n",
    "logs_loss = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maxlen = max([len(s) for s in sentences])\n",
    "\n",
    "idx2word = data_df['word'].unique().tolist()\n",
    "idx2word.append(\"ENDPAD\")\n",
    "n_words = len(idx2word)\n",
    "word2idx = {w: i for i, w in enumerate(idx2word)}\n",
    "\n",
    "idx2tag = data_df['tag'].unique().tolist()\n",
    "idx2tag.append('TAGPAD')\n",
    "n_tags = len(idx2tag)\n",
    "tag2idx = {t: i for i, t in enumerate(idx2tag)}\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=maxlen, sequences=X, padding=\"post\",value=n_words - 1)\n",
    "\n",
    "y = [[tag2idx[w[-1]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=maxlen, sequences=y, padding=\"post\", value=n_tags-1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10044 samples, validate on 4305 samples\n",
      "Epoch 1/6\n",
      "  128/10044 [..............................] - ETA: 12:41 - loss: 1.6979 - crf_viterbi_accuracy: 0.8569dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8568861\n",
      "  256/10044 [..............................] - ETA: 10:34 - loss: 1.6104 - crf_viterbi_accuracy: 0.8711dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8710592\n",
      "  384/10044 [>.............................] - ETA: 9:43 - loss: 1.5337 - crf_viterbi_accuracy: 0.8721 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.87211925\n",
      "  512/10044 [>.............................] - ETA: 9:20 - loss: 1.4564 - crf_viterbi_accuracy: 0.8676dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8676196\n",
      "  640/10044 [>.............................] - ETA: 9:02 - loss: 1.3625 - crf_viterbi_accuracy: 0.8678dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.86776817\n",
      "  768/10044 [=>............................] - ETA: 8:49 - loss: 1.2580 - crf_viterbi_accuracy: 0.8673dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8673257\n",
      "  896/10044 [=>............................] - ETA: 8:38 - loss: 1.1547 - crf_viterbi_accuracy: 0.8648dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.86479723\n",
      " 1024/10044 [==>...........................] - ETA: 8:27 - loss: 1.0620 - crf_viterbi_accuracy: 0.8656dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8656405\n",
      " 1152/10044 [==>...........................] - ETA: 8:17 - loss: 0.9880 - crf_viterbi_accuracy: 0.8675dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.867464\n",
      " 1280/10044 [==>...........................] - ETA: 8:08 - loss: 0.9290 - crf_viterbi_accuracy: 0.8694dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.869386\n",
      " 1408/10044 [===>..........................] - ETA: 7:59 - loss: 0.8845 - crf_viterbi_accuracy: 0.8685dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.86849475\n",
      " 1536/10044 [===>..........................] - ETA: 7:53 - loss: 0.8420 - crf_viterbi_accuracy: 0.8685dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8684837\n",
      " 1664/10044 [===>..........................] - ETA: 7:45 - loss: 0.8007 - crf_viterbi_accuracy: 0.8697dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.869655\n",
      " 1792/10044 [====>.........................] - ETA: 7:37 - loss: 0.7648 - crf_viterbi_accuracy: 0.8700dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.86997265\n",
      " 1920/10044 [====>.........................] - ETA: 7:29 - loss: 0.7324 - crf_viterbi_accuracy: 0.8703dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8702755\n",
      " 2048/10044 [=====>........................] - ETA: 7:21 - loss: 0.7023 - crf_viterbi_accuracy: 0.8711dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8710677\n",
      " 2176/10044 [=====>........................] - ETA: 7:13 - loss: 0.6769 - crf_viterbi_accuracy: 0.8714dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8713763\n",
      " 2304/10044 [=====>........................] - ETA: 7:05 - loss: 0.6527 - crf_viterbi_accuracy: 0.8729dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8728988\n",
      " 2432/10044 [======>.......................] - ETA: 6:57 - loss: 0.6317 - crf_viterbi_accuracy: 0.8741dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.87411195\n",
      " 2560/10044 [======>.......................] - ETA: 6:49 - loss: 0.6136 - crf_viterbi_accuracy: 0.8750dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8750206\n",
      " 2688/10044 [=======>......................] - ETA: 6:41 - loss: 0.5955 - crf_viterbi_accuracy: 0.8767dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8766625\n",
      " 2816/10044 [=======>......................] - ETA: 6:33 - loss: 0.5788 - crf_viterbi_accuracy: 0.8784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.87843794\n",
      " 2944/10044 [=======>......................] - ETA: 6:26 - loss: 0.5650 - crf_viterbi_accuracy: 0.8796dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8796291\n",
      " 3072/10044 [========>.....................] - ETA: 6:18 - loss: 0.5525 - crf_viterbi_accuracy: 0.8809dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8808622\n",
      " 3200/10044 [========>.....................] - ETA: 6:11 - loss: 0.5406 - crf_viterbi_accuracy: 0.8821dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.88207126\n",
      " 3328/10044 [========>.....................] - ETA: 6:03 - loss: 0.5284 - crf_viterbi_accuracy: 0.8836dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.88358086\n",
      " 3456/10044 [=========>....................] - ETA: 5:56 - loss: 0.5175 - crf_viterbi_accuracy: 0.8849dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.88486344\n",
      " 3584/10044 [=========>....................] - ETA: 5:49 - loss: 0.5078 - crf_viterbi_accuracy: 0.8861dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.88607174\n",
      " 3712/10044 [==========>...................] - ETA: 5:42 - loss: 0.4980 - crf_viterbi_accuracy: 0.8875dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8874899\n",
      " 3840/10044 [==========>...................] - ETA: 5:35 - loss: 0.4887 - crf_viterbi_accuracy: 0.8890dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.88901407\n",
      " 3968/10044 [==========>...................] - ETA: 5:28 - loss: 0.4798 - crf_viterbi_accuracy: 0.8906dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8906473\n",
      " 4096/10044 [===========>..................] - ETA: 5:20 - loss: 0.4718 - crf_viterbi_accuracy: 0.8923dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.89226264\n",
      " 4224/10044 [===========>..................] - ETA: 5:13 - loss: 0.4636 - crf_viterbi_accuracy: 0.8940dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8939708\n",
      " 4352/10044 [===========>..................] - ETA: 5:06 - loss: 0.4549 - crf_viterbi_accuracy: 0.8960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.8959546\n",
      " 4480/10044 [============>.................] - ETA: 4:59 - loss: 0.4466 - crf_viterbi_accuracy: 0.8980dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.89798117\n",
      " 4608/10044 [============>.................] - ETA: 4:52 - loss: 0.4388 - crf_viterbi_accuracy: 0.8999dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.89989513\n",
      " 4736/10044 [=============>................] - ETA: 4:45 - loss: 0.4312 - crf_viterbi_accuracy: 0.9017dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9016776\n",
      " 4864/10044 [=============>................] - ETA: 4:38 - loss: 0.4237 - crf_viterbi_accuracy: 0.9035dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9034736\n",
      " 4992/10044 [=============>................] - ETA: 4:31 - loss: 0.4168 - crf_viterbi_accuracy: 0.9052dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9051775\n",
      " 5120/10044 [==============>...............] - ETA: 4:24 - loss: 0.4097 - crf_viterbi_accuracy: 0.9069dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9068791\n",
      " 5248/10044 [==============>...............] - ETA: 4:17 - loss: 0.4031 - crf_viterbi_accuracy: 0.9085dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9084826\n",
      " 5376/10044 [===============>..............] - ETA: 4:11 - loss: 0.3965 - crf_viterbi_accuracy: 0.9101dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9101101\n",
      " 5504/10044 [===============>..............] - ETA: 4:04 - loss: 0.3904 - crf_viterbi_accuracy: 0.9116dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9116282\n",
      " 5632/10044 [===============>..............] - ETA: 3:57 - loss: 0.3843 - crf_viterbi_accuracy: 0.9131dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.91313225\n",
      " 5760/10044 [================>.............] - ETA: 3:50 - loss: 0.3783 - crf_viterbi_accuracy: 0.9146dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9145602\n",
      " 5888/10044 [================>.............] - ETA: 3:43 - loss: 0.3727 - crf_viterbi_accuracy: 0.9159dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.91585547\n",
      " 6016/10044 [================>.............] - ETA: 3:36 - loss: 0.3672 - crf_viterbi_accuracy: 0.9171dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.91707796\n",
      " 6144/10044 [=================>............] - ETA: 3:29 - loss: 0.3623 - crf_viterbi_accuracy: 0.9181dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9181444\n",
      " 6272/10044 [=================>............] - ETA: 3:22 - loss: 0.3575 - crf_viterbi_accuracy: 0.9191dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9191362\n",
      " 6400/10044 [==================>...........] - ETA: 3:15 - loss: 0.3528 - crf_viterbi_accuracy: 0.9201dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9201326\n",
      " 6528/10044 [==================>...........] - ETA: 3:08 - loss: 0.3480 - crf_viterbi_accuracy: 0.9212dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9211686\n",
      " 6656/10044 [==================>...........] - ETA: 3:01 - loss: 0.3434 - crf_viterbi_accuracy: 0.9221dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9221169\n",
      " 6784/10044 [===================>..........] - ETA: 2:55 - loss: 0.3392 - crf_viterbi_accuracy: 0.9230dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.92299545\n",
      " 6912/10044 [===================>..........] - ETA: 2:47 - loss: 0.3351 - crf_viterbi_accuracy: 0.9239dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9238658\n",
      " 7040/10044 [====================>.........] - ETA: 2:41 - loss: 0.3308 - crf_viterbi_accuracy: 0.9248dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9248352\n",
      " 7168/10044 [====================>.........] - ETA: 2:34 - loss: 0.3267 - crf_viterbi_accuracy: 0.9258dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.92575026\n",
      " 7296/10044 [====================>.........] - ETA: 2:27 - loss: 0.3228 - crf_viterbi_accuracy: 0.9267dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9266647\n",
      " 7424/10044 [=====================>........] - ETA: 2:20 - loss: 0.3191 - crf_viterbi_accuracy: 0.9275dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9274678\n",
      " 7552/10044 [=====================>........] - ETA: 2:13 - loss: 0.3154 - crf_viterbi_accuracy: 0.9283dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9283046\n",
      " 7680/10044 [=====================>........] - ETA: 2:06 - loss: 0.3118 - crf_viterbi_accuracy: 0.9291dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9291308\n",
      " 7808/10044 [======================>.......] - ETA: 1:59 - loss: 0.3084 - crf_viterbi_accuracy: 0.9299dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.92989135\n",
      " 7936/10044 [======================>.......] - ETA: 1:52 - loss: 0.3052 - crf_viterbi_accuracy: 0.9306dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9306497\n",
      " 8064/10044 [=======================>......] - ETA: 1:45 - loss: 0.3020 - crf_viterbi_accuracy: 0.9314dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9313708\n",
      " 8192/10044 [=======================>......] - ETA: 1:38 - loss: 0.2990 - crf_viterbi_accuracy: 0.9320dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9320456\n",
      " 8320/10044 [=======================>......] - ETA: 1:32 - loss: 0.2960 - crf_viterbi_accuracy: 0.9327dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.93270284\n",
      " 8448/10044 [========================>.....] - ETA: 1:25 - loss: 0.2931 - crf_viterbi_accuracy: 0.9333dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.93334746\n",
      " 8576/10044 [========================>.....] - ETA: 1:18 - loss: 0.2902 - crf_viterbi_accuracy: 0.9340dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.93399763\n",
      " 8704/10044 [========================>.....] - ETA: 1:11 - loss: 0.2872 - crf_viterbi_accuracy: 0.9346dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9346419\n",
      " 8832/10044 [=========================>....] - ETA: 1:04 - loss: 0.2844 - crf_viterbi_accuracy: 0.9352dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.93524545\n",
      " 8960/10044 [=========================>....] - ETA: 58s - loss: 0.2820 - crf_viterbi_accuracy: 0.9358 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9357784\n",
      " 9088/10044 [==========================>...] - ETA: 51s - loss: 0.2794 - crf_viterbi_accuracy: 0.9363dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9363411\n",
      " 9216/10044 [==========================>...] - ETA: 44s - loss: 0.2769 - crf_viterbi_accuracy: 0.9369dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.93691796\n",
      " 9344/10044 [==========================>...] - ETA: 37s - loss: 0.2746 - crf_viterbi_accuracy: 0.9374dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9374269\n",
      " 9472/10044 [===========================>..] - ETA: 30s - loss: 0.2723 - crf_viterbi_accuracy: 0.9380dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9379586\n",
      " 9600/10044 [===========================>..] - ETA: 23s - loss: 0.2701 - crf_viterbi_accuracy: 0.9384dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.93844837\n",
      " 9728/10044 [============================>.] - ETA: 16s - loss: 0.2679 - crf_viterbi_accuracy: 0.9389dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9389226\n",
      " 9856/10044 [============================>.] - ETA: 10s - loss: 0.2656 - crf_viterbi_accuracy: 0.9394dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.93942845\n",
      " 9984/10044 [============================>.] - ETA: 3s - loss: 0.2634 - crf_viterbi_accuracy: 0.9399 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9399391\n",
      "dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9404062\n",
      "10044/10044 [==============================] - 583s 58ms/step - loss: 0.2624 - crf_viterbi_accuracy: 0.9404 - val_loss: 0.0939 - val_crf_viterbi_accuracy: 0.9786\n",
      "Epoch 2/6\n",
      "  128/10044 [..............................] - ETA: 8:25 - loss: 0.0862 - crf_viterbi_accuracy: 0.9806dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98057246\n",
      "  256/10044 [..............................] - ETA: 8:22 - loss: 0.0934 - crf_viterbi_accuracy: 0.9786dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9786366\n",
      "  384/10044 [>.............................] - ETA: 8:16 - loss: 0.0952 - crf_viterbi_accuracy: 0.9777dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9777148\n",
      "  512/10044 [>.............................] - ETA: 8:13 - loss: 0.0970 - crf_viterbi_accuracy: 0.9772dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97723657\n",
      "  640/10044 [>.............................] - ETA: 8:06 - loss: 0.0970 - crf_viterbi_accuracy: 0.9771dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97711563\n",
      "  768/10044 [=>............................] - ETA: 7:58 - loss: 0.0958 - crf_viterbi_accuracy: 0.9776dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9775881\n",
      "  896/10044 [=>............................] - ETA: 7:51 - loss: 0.0951 - crf_viterbi_accuracy: 0.9777dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97765887\n",
      " 1024/10044 [==>...........................] - ETA: 7:45 - loss: 0.0952 - crf_viterbi_accuracy: 0.9776dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9775996\n",
      " 1152/10044 [==>...........................] - ETA: 7:40 - loss: 0.0939 - crf_viterbi_accuracy: 0.9779dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9779146\n",
      " 1280/10044 [==>...........................] - ETA: 7:34 - loss: 0.0931 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9781458\n",
      " 1408/10044 [===>..........................] - ETA: 7:27 - loss: 0.0921 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97837263\n",
      " 1536/10044 [===>..........................] - ETA: 7:21 - loss: 0.0923 - crf_viterbi_accuracy: 0.9783dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97827363\n",
      " 1664/10044 [===>..........................] - ETA: 7:14 - loss: 0.0924 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97823775\n",
      " 1792/10044 [====>.........................] - ETA: 7:08 - loss: 0.0924 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9782366\n",
      " 1920/10044 [====>.........................] - ETA: 7:01 - loss: 0.0919 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9783739\n",
      " 2048/10044 [=====>........................] - ETA: 6:55 - loss: 0.0921 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97823477\n",
      " 2176/10044 [=====>........................] - ETA: 6:48 - loss: 0.0925 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97808355\n",
      " 2304/10044 [=====>........................] - ETA: 6:42 - loss: 0.0918 - crf_viterbi_accuracy: 0.9783dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97825253\n",
      " 2432/10044 [======>.......................] - ETA: 6:35 - loss: 0.0915 - crf_viterbi_accuracy: 0.9783dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9782982\n",
      " 2560/10044 [======>.......................] - ETA: 6:29 - loss: 0.0914 - crf_viterbi_accuracy: 0.9783dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9782874\n",
      " 2688/10044 [=======>......................] - ETA: 6:23 - loss: 0.0906 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97841597\n",
      " 2816/10044 [=======>......................] - ETA: 6:16 - loss: 0.0905 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97840714\n",
      " 2944/10044 [=======>......................] - ETA: 6:10 - loss: 0.0902 - crf_viterbi_accuracy: 0.9785dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97845924\n",
      " 3072/10044 [========>.....................] - ETA: 6:03 - loss: 0.0900 - crf_viterbi_accuracy: 0.9785dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9784724\n",
      " 3200/10044 [========>.....................] - ETA: 5:57 - loss: 0.0899 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97844297\n",
      " 3328/10044 [========>.....................] - ETA: 5:50 - loss: 0.0902 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9783574\n",
      " 3456/10044 [=========>....................] - ETA: 5:43 - loss: 0.0898 - crf_viterbi_accuracy: 0.9785dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97845227\n",
      " 3584/10044 [=========>....................] - ETA: 5:37 - loss: 0.0899 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97842425\n",
      " 3712/10044 [==========>...................] - ETA: 5:30 - loss: 0.0899 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97837913\n",
      " 3840/10044 [==========>...................] - ETA: 5:23 - loss: 0.0899 - crf_viterbi_accuracy: 0.9783dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97832555\n",
      " 3968/10044 [==========>...................] - ETA: 5:17 - loss: 0.0897 - crf_viterbi_accuracy: 0.9784dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97837347\n",
      " 4096/10044 [===========>..................] - ETA: 5:10 - loss: 0.0897 - crf_viterbi_accuracy: 0.9783dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9783039\n",
      " 4224/10044 [===========>..................] - ETA: 5:04 - loss: 0.0900 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9782155\n",
      " 4352/10044 [===========>..................] - ETA: 4:57 - loss: 0.0899 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9781812\n",
      " 4480/10044 [============>.................] - ETA: 4:51 - loss: 0.0898 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9782258\n",
      " 4608/10044 [============>.................] - ETA: 4:44 - loss: 0.0899 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97818923\n",
      " 4736/10044 [=============>................] - ETA: 4:38 - loss: 0.0896 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97824806\n",
      " 4864/10044 [=============>................] - ETA: 4:31 - loss: 0.0897 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97818005\n",
      " 4992/10044 [=============>................] - ETA: 4:25 - loss: 0.0895 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97819704\n",
      " 5120/10044 [==============>...............] - ETA: 4:18 - loss: 0.0892 - crf_viterbi_accuracy: 0.9783dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.978253\n",
      " 5248/10044 [==============>...............] - ETA: 4:12 - loss: 0.0892 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9782269\n",
      " 5376/10044 [===============>..............] - ETA: 4:05 - loss: 0.0892 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97818065\n",
      " 5504/10044 [===============>..............] - ETA: 3:58 - loss: 0.0892 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9781414\n",
      " 5632/10044 [===============>..............] - ETA: 3:51 - loss: 0.0892 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97810084\n",
      " 5760/10044 [================>.............] - ETA: 3:45 - loss: 0.0892 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780606\n",
      " 5888/10044 [================>.............] - ETA: 3:38 - loss: 0.0891 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97806257\n",
      " 6016/10044 [================>.............] - ETA: 3:31 - loss: 0.0889 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97811306\n",
      " 6144/10044 [=================>............] - ETA: 3:25 - loss: 0.0889 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97806495\n",
      " 6272/10044 [=================>............] - ETA: 3:18 - loss: 0.0887 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97807235\n",
      " 6400/10044 [==================>...........] - ETA: 3:11 - loss: 0.0887 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780532\n",
      " 6528/10044 [==================>...........] - ETA: 3:04 - loss: 0.0886 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97804165\n",
      " 6656/10044 [==================>...........] - ETA: 2:58 - loss: 0.0886 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780225\n",
      " 6784/10044 [===================>..........] - ETA: 2:51 - loss: 0.0883 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780784\n",
      " 6912/10044 [===================>..........] - ETA: 2:44 - loss: 0.0882 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780721\n",
      " 7040/10044 [====================>.........] - ETA: 2:38 - loss: 0.0882 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780422\n",
      " 7168/10044 [====================>.........] - ETA: 2:31 - loss: 0.0882 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9779714\n",
      " 7296/10044 [====================>.........] - ETA: 2:24 - loss: 0.0880 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.978\n",
      " 7424/10044 [=====================>........] - ETA: 2:17 - loss: 0.0878 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780038\n",
      " 7552/10044 [=====================>........] - ETA: 2:11 - loss: 0.0878 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9779747\n",
      " 7680/10044 [=====================>........] - ETA: 2:04 - loss: 0.0876 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9779673\n",
      " 7808/10044 [======================>.......] - ETA: 1:57 - loss: 0.0874 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.978018\n",
      " 7936/10044 [======================>.......] - ETA: 1:50 - loss: 0.0872 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97801906\n",
      " 8064/10044 [=======================>......] - ETA: 1:44 - loss: 0.0871 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780146\n",
      " 8192/10044 [=======================>......] - ETA: 1:37 - loss: 0.0870 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97799295\n",
      " 8320/10044 [=======================>......] - ETA: 1:30 - loss: 0.0869 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780007\n",
      " 8448/10044 [========================>.....] - ETA: 1:23 - loss: 0.0868 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97800726\n",
      " 8576/10044 [========================>.....] - ETA: 1:17 - loss: 0.0866 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780001\n",
      " 8704/10044 [========================>.....] - ETA: 1:10 - loss: 0.0864 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780298\n",
      " 8832/10044 [=========================>....] - ETA: 1:03 - loss: 0.0861 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780667\n",
      " 8960/10044 [=========================>....] - ETA: 56s - loss: 0.0860 - crf_viterbi_accuracy: 0.9781 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.978063\n",
      " 9088/10044 [==========================>...] - ETA: 50s - loss: 0.0859 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780642\n",
      " 9216/10044 [==========================>...] - ETA: 43s - loss: 0.0857 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780712\n",
      " 9344/10044 [==========================>...] - ETA: 36s - loss: 0.0856 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780752\n",
      " 9472/10044 [===========================>..] - ETA: 30s - loss: 0.0855 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97805107\n",
      " 9600/10044 [===========================>..] - ETA: 23s - loss: 0.0853 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780809\n",
      " 9728/10044 [============================>.] - ETA: 16s - loss: 0.0852 - crf_viterbi_accuracy: 0.9781dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97807735\n",
      " 9856/10044 [============================>.] - ETA: 9s - loss: 0.0851 - crf_viterbi_accuracy: 0.9780 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780477\n",
      " 9984/10044 [============================>.] - ETA: 3s - loss: 0.0850 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9780376\n",
      "dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97806174\n",
      "10044/10044 [==============================] - 576s 57ms/step - loss: 0.0849 - crf_viterbi_accuracy: 0.9781 - val_loss: 0.0698 - val_crf_viterbi_accuracy: 0.9787\n",
      "Epoch 3/6\n",
      "  128/10044 [..............................] - ETA: 8:46 - loss: 0.0726 - crf_viterbi_accuracy: 0.9779dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97794527\n",
      "  256/10044 [..............................] - ETA: 8:43 - loss: 0.0703 - crf_viterbi_accuracy: 0.9788dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9788095\n",
      "  384/10044 [>.............................] - ETA: 8:34 - loss: 0.0733 - crf_viterbi_accuracy: 0.9773dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97732306\n",
      "  512/10044 [>.............................] - ETA: 8:26 - loss: 0.0711 - crf_viterbi_accuracy: 0.9780dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9779971\n",
      "  640/10044 [>.............................] - ETA: 8:23 - loss: 0.0687 - crf_viterbi_accuracy: 0.9787dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9786643\n",
      "  768/10044 [=>............................] - ETA: 8:16 - loss: 0.0686 - crf_viterbi_accuracy: 0.9788dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.978798\n",
      "  896/10044 [=>............................] - ETA: 8:11 - loss: 0.0697 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9782317\n",
      " 1024/10044 [==>...........................] - ETA: 8:03 - loss: 0.0697 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9781527\n",
      " 1152/10044 [==>...........................] - ETA: 7:55 - loss: 0.0703 - crf_viterbi_accuracy: 0.9779dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9779069\n",
      " 1280/10044 [==>...........................] - ETA: 7:48 - loss: 0.0696 - crf_viterbi_accuracy: 0.9782dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9781803\n",
      " 1408/10044 [===>..........................] - ETA: 7:41 - loss: 0.0685 - crf_viterbi_accuracy: 0.9785dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97847944\n",
      " 1536/10044 [===>..........................] - ETA: 7:33 - loss: 0.0681 - crf_viterbi_accuracy: 0.9786dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.978579\n",
      " 1664/10044 [===>..........................] - ETA: 7:25 - loss: 0.0681 - crf_viterbi_accuracy: 0.9786dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9785621\n",
      " 1792/10044 [====>.........................] - ETA: 7:18 - loss: 0.0680 - crf_viterbi_accuracy: 0.9787dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97866124\n",
      " 1920/10044 [====>.........................] - ETA: 7:09 - loss: 0.0681 - crf_viterbi_accuracy: 0.9786dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97858125\n",
      " 2048/10044 [=====>........................] - ETA: 7:02 - loss: 0.0680 - crf_viterbi_accuracy: 0.9786dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9785544\n",
      " 2176/10044 [=====>........................] - ETA: 6:55 - loss: 0.0677 - crf_viterbi_accuracy: 0.9786dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97862434\n",
      " 2304/10044 [=====>........................] - ETA: 6:48 - loss: 0.0671 - crf_viterbi_accuracy: 0.9788dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.978844\n",
      " 2432/10044 [======>.......................] - ETA: 6:41 - loss: 0.0663 - crf_viterbi_accuracy: 0.9791dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97909504\n",
      " 2560/10044 [======>.......................] - ETA: 6:34 - loss: 0.0657 - crf_viterbi_accuracy: 0.9793dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97928303\n",
      " 2688/10044 [=======>......................] - ETA: 6:27 - loss: 0.0654 - crf_viterbi_accuracy: 0.9793dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97934115\n",
      " 2816/10044 [=======>......................] - ETA: 6:20 - loss: 0.0655 - crf_viterbi_accuracy: 0.9793dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9792526\n",
      " 2944/10044 [=======>......................] - ETA: 6:12 - loss: 0.0651 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97935504\n",
      " 3072/10044 [========>.....................] - ETA: 6:05 - loss: 0.0650 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9793539\n",
      " 3200/10044 [========>.....................] - ETA: 5:58 - loss: 0.0648 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9793916\n",
      " 3328/10044 [========>.....................] - ETA: 5:52 - loss: 0.0648 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9793519\n",
      " 3456/10044 [=========>....................] - ETA: 5:45 - loss: 0.0645 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97942775\n",
      " 3584/10044 [=========>....................] - ETA: 5:38 - loss: 0.0645 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9793896\n",
      " 3712/10044 [==========>...................] - ETA: 5:31 - loss: 0.0643 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9794399\n",
      " 3840/10044 [==========>...................] - ETA: 5:25 - loss: 0.0641 - crf_viterbi_accuracy: 0.9795dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9794938\n",
      " 3968/10044 [==========>...................] - ETA: 5:18 - loss: 0.0642 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.979377\n",
      " 4096/10044 [===========>..................] - ETA: 5:11 - loss: 0.0641 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9793711\n",
      " 4224/10044 [===========>..................] - ETA: 5:04 - loss: 0.0640 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9793509\n",
      " 4352/10044 [===========>..................] - ETA: 4:57 - loss: 0.0638 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97938883\n",
      " 4480/10044 [============>.................] - ETA: 4:50 - loss: 0.0637 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9794306\n",
      " 4608/10044 [============>.................] - ETA: 4:44 - loss: 0.0637 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97939134\n",
      " 4736/10044 [=============>................] - ETA: 4:37 - loss: 0.0636 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97939146\n",
      " 4864/10044 [=============>................] - ETA: 4:30 - loss: 0.0634 - crf_viterbi_accuracy: 0.9794dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9793989\n",
      " 4992/10044 [=============>................] - ETA: 4:23 - loss: 0.0631 - crf_viterbi_accuracy: 0.9795dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97948223\n",
      " 5120/10044 [==============>...............] - ETA: 4:17 - loss: 0.0626 - crf_viterbi_accuracy: 0.9796dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9796028\n",
      " 5248/10044 [==============>...............] - ETA: 4:10 - loss: 0.0625 - crf_viterbi_accuracy: 0.9796dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9795877\n",
      " 5376/10044 [===============>..............] - ETA: 4:04 - loss: 0.0623 - crf_viterbi_accuracy: 0.9796dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97963744\n",
      " 5504/10044 [===============>..............] - ETA: 3:57 - loss: 0.0620 - crf_viterbi_accuracy: 0.9797dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9796833\n",
      " 5632/10044 [===============>..............] - ETA: 3:50 - loss: 0.0620 - crf_viterbi_accuracy: 0.9796dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97964376\n",
      " 5760/10044 [================>.............] - ETA: 3:44 - loss: 0.0619 - crf_viterbi_accuracy: 0.9796dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9796337\n",
      " 5888/10044 [================>.............] - ETA: 3:38 - loss: 0.0618 - crf_viterbi_accuracy: 0.9797dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97965705\n",
      " 6016/10044 [================>.............] - ETA: 3:31 - loss: 0.0616 - crf_viterbi_accuracy: 0.9797dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9796794\n",
      " 6144/10044 [=================>............] - ETA: 3:24 - loss: 0.0614 - crf_viterbi_accuracy: 0.9797dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.979698\n",
      " 6272/10044 [=================>............] - ETA: 3:18 - loss: 0.0613 - crf_viterbi_accuracy: 0.9797dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9797356\n",
      " 6400/10044 [==================>...........] - ETA: 3:11 - loss: 0.0611 - crf_viterbi_accuracy: 0.9798dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97977865\n",
      " 6528/10044 [==================>...........] - ETA: 3:05 - loss: 0.0608 - crf_viterbi_accuracy: 0.9798dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.97982407\n",
      " 6656/10044 [==================>...........] - ETA: 2:58 - loss: 0.0606 - crf_viterbi_accuracy: 0.9799dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9798823\n",
      " 6784/10044 [===================>..........] - ETA: 2:51 - loss: 0.0603 - crf_viterbi_accuracy: 0.9799dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.979941\n",
      " 6912/10044 [===================>..........] - ETA: 2:45 - loss: 0.0600 - crf_viterbi_accuracy: 0.9800dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9800091\n",
      " 7040/10044 [====================>.........] - ETA: 2:38 - loss: 0.0597 - crf_viterbi_accuracy: 0.9801dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9800948\n",
      " 7168/10044 [====================>.........] - ETA: 2:32 - loss: 0.0594 - crf_viterbi_accuracy: 0.9802dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9801577\n",
      " 7296/10044 [====================>.........] - ETA: 2:25 - loss: 0.0592 - crf_viterbi_accuracy: 0.9802dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98020494\n",
      " 7424/10044 [=====================>........] - ETA: 2:18 - loss: 0.0590 - crf_viterbi_accuracy: 0.9802dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9802435\n",
      " 7552/10044 [=====================>........] - ETA: 2:12 - loss: 0.0588 - crf_viterbi_accuracy: 0.9803dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9802783\n",
      " 7680/10044 [=====================>........] - ETA: 2:05 - loss: 0.0586 - crf_viterbi_accuracy: 0.9803dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98034436\n",
      " 7808/10044 [======================>.......] - ETA: 1:58 - loss: 0.0584 - crf_viterbi_accuracy: 0.9804dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98038435\n",
      " 7936/10044 [======================>.......] - ETA: 1:52 - loss: 0.0581 - crf_viterbi_accuracy: 0.9804dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9804454\n",
      " 8064/10044 [=======================>......] - ETA: 1:45 - loss: 0.0579 - crf_viterbi_accuracy: 0.9805dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98049676\n",
      " 8192/10044 [=======================>......] - ETA: 1:38 - loss: 0.0576 - crf_viterbi_accuracy: 0.9806dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98057896\n",
      " 8320/10044 [=======================>......] - ETA: 1:31 - loss: 0.0574 - crf_viterbi_accuracy: 0.9806dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98063093\n",
      " 8448/10044 [========================>.....] - ETA: 1:24 - loss: 0.0571 - crf_viterbi_accuracy: 0.9807dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9806835\n",
      " 8576/10044 [========================>.....] - ETA: 1:18 - loss: 0.0569 - crf_viterbi_accuracy: 0.9807dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9807293\n",
      " 8704/10044 [========================>.....] - ETA: 1:11 - loss: 0.0568 - crf_viterbi_accuracy: 0.9807dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9807463\n",
      " 8832/10044 [=========================>....] - ETA: 1:04 - loss: 0.0566 - crf_viterbi_accuracy: 0.9808dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9807949\n",
      " 8960/10044 [=========================>....] - ETA: 57s - loss: 0.0564 - crf_viterbi_accuracy: 0.9808 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98084706\n",
      " 9088/10044 [==========================>...] - ETA: 50s - loss: 0.0561 - crf_viterbi_accuracy: 0.9809dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9809337\n",
      " 9216/10044 [==========================>...] - ETA: 43s - loss: 0.0560 - crf_viterbi_accuracy: 0.9809dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.980946\n",
      " 9344/10044 [==========================>...] - ETA: 37s - loss: 0.0557 - crf_viterbi_accuracy: 0.9810dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.981011\n",
      " 9472/10044 [===========================>..] - ETA: 30s - loss: 0.0555 - crf_viterbi_accuracy: 0.9811dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9810518\n",
      " 9600/10044 [===========================>..] - ETA: 23s - loss: 0.0553 - crf_viterbi_accuracy: 0.9811dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98111725\n",
      " 9728/10044 [============================>.] - ETA: 16s - loss: 0.0551 - crf_viterbi_accuracy: 0.9812dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9811574\n",
      " 9856/10044 [============================>.] - ETA: 9s - loss: 0.0548 - crf_viterbi_accuracy: 0.9812 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98122704\n",
      " 9984/10044 [============================>.] - ETA: 3s - loss: 0.0546 - crf_viterbi_accuracy: 0.9813dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98129046\n",
      "dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98135924\n",
      "10044/10044 [==============================] - 581s 58ms/step - loss: 0.0545 - crf_viterbi_accuracy: 0.9814 - val_loss: 0.0383 - val_crf_viterbi_accuracy: 0.9858\n",
      "Epoch 4/6\n",
      "  128/10044 [..............................] - ETA: 8:45 - loss: 0.0362 - crf_viterbi_accuracy: 0.9862dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9862417\n",
      "  256/10044 [..............................] - ETA: 8:43 - loss: 0.0363 - crf_viterbi_accuracy: 0.9862dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9862071\n",
      "  384/10044 [>.............................] - ETA: 8:54 - loss: 0.0352 - crf_viterbi_accuracy: 0.9867dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9867026\n",
      "  512/10044 [>.............................] - ETA: 8:41 - loss: 0.0359 - crf_viterbi_accuracy: 0.9864dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98639727\n",
      "  640/10044 [>.............................] - ETA: 8:29 - loss: 0.0360 - crf_viterbi_accuracy: 0.9864dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9863938\n",
      "  768/10044 [=>............................] - ETA: 8:18 - loss: 0.0356 - crf_viterbi_accuracy: 0.9865dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9865183\n",
      "  896/10044 [=>............................] - ETA: 8:08 - loss: 0.0358 - crf_viterbi_accuracy: 0.9864dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98640966\n",
      " 1024/10044 [==>...........................] - ETA: 8:00 - loss: 0.0354 - crf_viterbi_accuracy: 0.9867dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98668253\n",
      " 1152/10044 [==>...........................] - ETA: 7:52 - loss: 0.0350 - crf_viterbi_accuracy: 0.9869dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9868717\n",
      " 1280/10044 [==>...........................] - ETA: 7:47 - loss: 0.0344 - crf_viterbi_accuracy: 0.9872dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98715436\n",
      " 1408/10044 [===>..........................] - ETA: 7:39 - loss: 0.0341 - crf_viterbi_accuracy: 0.9872dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.987216\n",
      " 1536/10044 [===>..........................] - ETA: 7:33 - loss: 0.0337 - crf_viterbi_accuracy: 0.9873dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98732495\n",
      " 1664/10044 [===>..........................] - ETA: 7:25 - loss: 0.0332 - crf_viterbi_accuracy: 0.9876dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9875607\n",
      " 1792/10044 [====>.........................] - ETA: 7:18 - loss: 0.0329 - crf_viterbi_accuracy: 0.9877dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9876739\n",
      " 1920/10044 [====>.........................] - ETA: 7:10 - loss: 0.0325 - crf_viterbi_accuracy: 0.9879dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9878596\n",
      " 2048/10044 [=====>........................] - ETA: 7:02 - loss: 0.0325 - crf_viterbi_accuracy: 0.9878dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9878103\n",
      " 2176/10044 [=====>........................] - ETA: 6:55 - loss: 0.0328 - crf_viterbi_accuracy: 0.9877dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98774654\n",
      " 2304/10044 [=====>........................] - ETA: 6:49 - loss: 0.0324 - crf_viterbi_accuracy: 0.9879dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9878781\n",
      " 2432/10044 [======>.......................] - ETA: 6:43 - loss: 0.0324 - crf_viterbi_accuracy: 0.9879dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9879375\n",
      " 2560/10044 [======>.......................] - ETA: 6:36 - loss: 0.0323 - crf_viterbi_accuracy: 0.9880dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9879979\n",
      " 2688/10044 [=======>......................] - ETA: 6:29 - loss: 0.0320 - crf_viterbi_accuracy: 0.9881dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9881316\n",
      " 2816/10044 [=======>......................] - ETA: 6:22 - loss: 0.0321 - crf_viterbi_accuracy: 0.9881dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98810536\n",
      " 2944/10044 [=======>......................] - ETA: 6:15 - loss: 0.0321 - crf_viterbi_accuracy: 0.9881dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98811746\n",
      " 3072/10044 [========>.....................] - ETA: 6:08 - loss: 0.0320 - crf_viterbi_accuracy: 0.9881dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98814875\n",
      " 3200/10044 [========>.....................] - ETA: 6:00 - loss: 0.0318 - crf_viterbi_accuracy: 0.9883dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.988255\n",
      " 3328/10044 [========>.....................] - ETA: 5:53 - loss: 0.0316 - crf_viterbi_accuracy: 0.9884dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98838234\n",
      " 3456/10044 [=========>....................] - ETA: 5:46 - loss: 0.0314 - crf_viterbi_accuracy: 0.9885dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98848486\n",
      " 3584/10044 [=========>....................] - ETA: 5:40 - loss: 0.0314 - crf_viterbi_accuracy: 0.9885dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9885455\n",
      " 3712/10044 [==========>...................] - ETA: 5:33 - loss: 0.0313 - crf_viterbi_accuracy: 0.9886dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9885948\n",
      " 3840/10044 [==========>...................] - ETA: 5:26 - loss: 0.0312 - crf_viterbi_accuracy: 0.9887dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98865\n",
      " 3968/10044 [==========>...................] - ETA: 5:19 - loss: 0.0310 - crf_viterbi_accuracy: 0.9887dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9887217\n",
      " 4096/10044 [===========>..................] - ETA: 5:12 - loss: 0.0310 - crf_viterbi_accuracy: 0.9887dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98874146\n",
      " 4224/10044 [===========>..................] - ETA: 5:05 - loss: 0.0308 - crf_viterbi_accuracy: 0.9889dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9888605\n",
      " 4352/10044 [===========>..................] - ETA: 4:59 - loss: 0.0307 - crf_viterbi_accuracy: 0.9889dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.988879\n",
      " 4480/10044 [============>.................] - ETA: 4:52 - loss: 0.0306 - crf_viterbi_accuracy: 0.9889dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98894197\n",
      " 4608/10044 [============>.................] - ETA: 4:45 - loss: 0.0306 - crf_viterbi_accuracy: 0.9890dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98898983\n",
      " 4736/10044 [=============>................] - ETA: 4:38 - loss: 0.0304 - crf_viterbi_accuracy: 0.9890dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9890445\n",
      " 4864/10044 [=============>................] - ETA: 4:32 - loss: 0.0303 - crf_viterbi_accuracy: 0.9891dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9891272\n",
      " 4992/10044 [=============>................] - ETA: 4:25 - loss: 0.0302 - crf_viterbi_accuracy: 0.9892dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9891649\n",
      " 5120/10044 [==============>...............] - ETA: 4:18 - loss: 0.0301 - crf_viterbi_accuracy: 0.9892dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98920935\n",
      " 5248/10044 [==============>...............] - ETA: 4:11 - loss: 0.0299 - crf_viterbi_accuracy: 0.9893dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9893022\n",
      " 5376/10044 [===============>..............] - ETA: 4:05 - loss: 0.0299 - crf_viterbi_accuracy: 0.9893dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9893462\n",
      " 5504/10044 [===============>..............] - ETA: 3:58 - loss: 0.0298 - crf_viterbi_accuracy: 0.9894dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9894026\n",
      " 5632/10044 [===============>..............] - ETA: 3:51 - loss: 0.0295 - crf_viterbi_accuracy: 0.9895dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9895146\n",
      " 5760/10044 [================>.............] - ETA: 3:44 - loss: 0.0295 - crf_viterbi_accuracy: 0.9896dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.989574\n",
      " 5888/10044 [================>.............] - ETA: 3:38 - loss: 0.0293 - crf_viterbi_accuracy: 0.9896dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9896399\n",
      " 6016/10044 [================>.............] - ETA: 3:31 - loss: 0.0292 - crf_viterbi_accuracy: 0.9897dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9897\n",
      " 6144/10044 [=================>............] - ETA: 3:24 - loss: 0.0291 - crf_viterbi_accuracy: 0.9897dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9897446\n",
      " 6272/10044 [=================>............] - ETA: 3:17 - loss: 0.0289 - crf_viterbi_accuracy: 0.9898dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.98979026\n",
      " 6400/10044 [==================>...........] - ETA: 3:11 - loss: 0.0288 - crf_viterbi_accuracy: 0.9899dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9898644\n",
      " 6528/10044 [==================>...........] - ETA: 3:04 - loss: 0.0287 - crf_viterbi_accuracy: 0.9899dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9898923\n",
      " 6656/10044 [==================>...........] - ETA: 2:57 - loss: 0.0286 - crf_viterbi_accuracy: 0.9899dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9899471\n",
      " 6784/10044 [===================>..........] - ETA: 2:51 - loss: 0.0285 - crf_viterbi_accuracy: 0.9900dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9899789\n",
      " 6912/10044 [===================>..........] - ETA: 2:44 - loss: 0.0283 - crf_viterbi_accuracy: 0.9900dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9900326\n",
      " 7040/10044 [====================>.........] - ETA: 2:37 - loss: 0.0282 - crf_viterbi_accuracy: 0.9901dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9900781\n",
      " 7168/10044 [====================>.........] - ETA: 2:31 - loss: 0.0281 - crf_viterbi_accuracy: 0.9901dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99014175\n",
      " 7296/10044 [====================>.........] - ETA: 2:24 - loss: 0.0282 - crf_viterbi_accuracy: 0.9902dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9901558\n",
      " 7424/10044 [=====================>........] - ETA: 2:17 - loss: 0.0281 - crf_viterbi_accuracy: 0.9902dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99020755\n",
      " 7552/10044 [=====================>........] - ETA: 2:11 - loss: 0.0280 - crf_viterbi_accuracy: 0.9902dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99024224\n",
      " 7680/10044 [=====================>........] - ETA: 2:04 - loss: 0.0279 - crf_viterbi_accuracy: 0.9903dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9902908\n",
      " 7808/10044 [======================>.......] - ETA: 1:57 - loss: 0.0279 - crf_viterbi_accuracy: 0.9903dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99033326\n",
      " 7936/10044 [======================>.......] - ETA: 1:51 - loss: 0.0277 - crf_viterbi_accuracy: 0.9904dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9903955\n",
      " 8064/10044 [=======================>......] - ETA: 1:44 - loss: 0.0277 - crf_viterbi_accuracy: 0.9904dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99041843\n",
      " 8192/10044 [=======================>......] - ETA: 1:38 - loss: 0.0276 - crf_viterbi_accuracy: 0.9905dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99046123\n",
      " 8320/10044 [=======================>......] - ETA: 1:31 - loss: 0.0275 - crf_viterbi_accuracy: 0.9905dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.990491\n",
      " 8448/10044 [========================>.....] - ETA: 1:25 - loss: 0.0274 - crf_viterbi_accuracy: 0.9905dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9905334\n",
      " 8576/10044 [========================>.....] - ETA: 1:18 - loss: 0.0274 - crf_viterbi_accuracy: 0.9906dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9905891\n",
      " 8704/10044 [========================>.....] - ETA: 1:11 - loss: 0.0273 - crf_viterbi_accuracy: 0.9906dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99062586\n",
      " 8832/10044 [=========================>....] - ETA: 1:04 - loss: 0.0272 - crf_viterbi_accuracy: 0.9907dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9906875\n",
      " 8960/10044 [=========================>....] - ETA: 58s - loss: 0.0271 - crf_viterbi_accuracy: 0.9907 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9907395\n",
      " 9088/10044 [==========================>...] - ETA: 51s - loss: 0.0270 - crf_viterbi_accuracy: 0.9908dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9907765\n",
      " 9216/10044 [==========================>...] - ETA: 44s - loss: 0.0269 - crf_viterbi_accuracy: 0.9908dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9908067\n",
      " 9344/10044 [==========================>...] - ETA: 37s - loss: 0.0268 - crf_viterbi_accuracy: 0.9908dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9908493\n",
      " 9472/10044 [===========================>..] - ETA: 30s - loss: 0.0267 - crf_viterbi_accuracy: 0.9909dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9908936\n",
      " 9600/10044 [===========================>..] - ETA: 23s - loss: 0.0266 - crf_viterbi_accuracy: 0.9909dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99091727\n",
      " 9728/10044 [============================>.] - ETA: 16s - loss: 0.0266 - crf_viterbi_accuracy: 0.9909dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9909485\n",
      " 9856/10044 [============================>.] - ETA: 10s - loss: 0.0265 - crf_viterbi_accuracy: 0.9910dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9909934\n",
      " 9984/10044 [============================>.] - ETA: 3s - loss: 0.0264 - crf_viterbi_accuracy: 0.9910 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9910423\n",
      "dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99109966\n",
      "10044/10044 [==============================] - 609s 61ms/step - loss: 0.0263 - crf_viterbi_accuracy: 0.9911 - val_loss: 0.0227 - val_crf_viterbi_accuracy: 0.9931\n",
      "Epoch 5/6\n",
      "  128/10044 [..............................] - ETA: 11:31 - loss: 0.0181 - crf_viterbi_accuracy: 0.9956dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99564433\n",
      "  256/10044 [..............................] - ETA: 11:33 - loss: 0.0186 - crf_viterbi_accuracy: 0.9949dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9949184\n",
      "  384/10044 [>.............................] - ETA: 11:40 - loss: 0.0177 - crf_viterbi_accuracy: 0.9950dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.994953\n",
      "  512/10044 [>.............................] - ETA: 11:38 - loss: 0.0166 - crf_viterbi_accuracy: 0.9953dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9952814\n",
      "  640/10044 [>.............................] - ETA: 11:27 - loss: 0.0160 - crf_viterbi_accuracy: 0.9955dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9954923\n",
      "  768/10044 [=>............................] - ETA: 11:21 - loss: 0.0160 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9954485\n",
      "  896/10044 [=>............................] - ETA: 11:12 - loss: 0.0165 - crf_viterbi_accuracy: 0.9952dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9952296\n",
      " 1024/10044 [==>...........................] - ETA: 11:01 - loss: 0.0165 - crf_viterbi_accuracy: 0.9952dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9952469\n",
      " 1152/10044 [==>...........................] - ETA: 10:53 - loss: 0.0169 - crf_viterbi_accuracy: 0.9952dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99519116\n",
      " 1280/10044 [==>...........................] - ETA: 10:44 - loss: 0.0164 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.995354\n",
      " 1408/10044 [===>..........................] - ETA: 10:32 - loss: 0.0163 - crf_viterbi_accuracy: 0.9953dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9953427\n",
      " 1536/10044 [===>..........................] - ETA: 10:21 - loss: 0.0159 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99543697\n",
      " 1664/10044 [===>..........................] - ETA: 10:12 - loss: 0.0157 - crf_viterbi_accuracy: 0.9955dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99549013\n",
      " 1792/10044 [====>.........................] - ETA: 10:04 - loss: 0.0156 - crf_viterbi_accuracy: 0.9956dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99556047\n",
      " 1920/10044 [====>.........................] - ETA: 9:54 - loss: 0.0156 - crf_viterbi_accuracy: 0.9956 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99556607\n",
      " 2048/10044 [=====>........................] - ETA: 9:45 - loss: 0.0156 - crf_viterbi_accuracy: 0.9955dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99552774\n",
      " 2176/10044 [=====>........................] - ETA: 9:38 - loss: 0.0155 - crf_viterbi_accuracy: 0.9955dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9954858\n",
      " 2304/10044 [=====>........................] - ETA: 9:31 - loss: 0.0156 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9954101\n",
      " 2432/10044 [======>.......................] - ETA: 9:22 - loss: 0.0156 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9953533\n",
      " 2560/10044 [======>.......................] - ETA: 9:14 - loss: 0.0157 - crf_viterbi_accuracy: 0.9953dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9953437\n",
      " 2688/10044 [=======>......................] - ETA: 9:02 - loss: 0.0155 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99544036\n",
      " 2816/10044 [=======>......................] - ETA: 8:54 - loss: 0.0156 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9953962\n",
      " 2944/10044 [=======>......................] - ETA: 8:45 - loss: 0.0155 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99543405\n",
      " 3072/10044 [========>.....................] - ETA: 8:36 - loss: 0.0155 - crf_viterbi_accuracy: 0.9954dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99543995\n",
      " 3200/10044 [========>.....................] - ETA: 8:26 - loss: 0.0154 - crf_viterbi_accuracy: 0.9955dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99548125\n",
      " 3328/10044 [========>.....................] - ETA: 8:15 - loss: 0.0153 - crf_viterbi_accuracy: 0.9955dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99553806\n",
      " 3456/10044 [=========>....................] - ETA: 8:01 - loss: 0.0152 - crf_viterbi_accuracy: 0.9956dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9955701\n",
      " 3584/10044 [=========>....................] - ETA: 7:46 - loss: 0.0152 - crf_viterbi_accuracy: 0.9956dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99558264\n",
      " 3712/10044 [==========>...................] - ETA: 2:18:33 - loss: 0.0151 - crf_viterbi_accuracy: 0.9956dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9956253\n",
      " 3840/10044 [==========>...................] - ETA: 2:11:19 - loss: 0.0151 - crf_viterbi_accuracy: 0.9956dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99563056\n",
      " 3968/10044 [==========>...................] - ETA: 2:04:32 - loss: 0.0150 - crf_viterbi_accuracy: 0.9957dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9956868\n",
      " 4096/10044 [===========>..................] - ETA: 1:58:11 - loss: 0.0149 - crf_viterbi_accuracy: 0.9957dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99570924\n",
      " 4224/10044 [===========>..................] - ETA: 1:52:16 - loss: 0.0149 - crf_viterbi_accuracy: 0.9957dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9957094\n",
      " 4352/10044 [===========>..................] - ETA: 1:46:42 - loss: 0.0148 - crf_viterbi_accuracy: 0.9957dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9957299\n",
      " 4480/10044 [============>.................] - ETA: 1:41:27 - loss: 0.0147 - crf_viterbi_accuracy: 0.9957dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99574715\n",
      " 4608/10044 [============>.................] - ETA: 1:36:29 - loss: 0.0147 - crf_viterbi_accuracy: 0.9958dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99575585\n",
      " 4736/10044 [=============>................] - ETA: 1:31:47 - loss: 0.0146 - crf_viterbi_accuracy: 0.9958dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9957884\n",
      " 4864/10044 [=============>................] - ETA: 1:27:20 - loss: 0.0145 - crf_viterbi_accuracy: 0.9958dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9958027\n",
      " 4992/10044 [=============>................] - ETA: 1:23:05 - loss: 0.0145 - crf_viterbi_accuracy: 0.9958dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9958217\n",
      " 5120/10044 [==============>...............] - ETA: 1:19:04 - loss: 0.0144 - crf_viterbi_accuracy: 0.9958dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99584836\n",
      " 5248/10044 [==============>...............] - ETA: 1:15:14 - loss: 0.0143 - crf_viterbi_accuracy: 0.9959dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.995862\n",
      " 5376/10044 [===============>..............] - ETA: 1:11:34 - loss: 0.0143 - crf_viterbi_accuracy: 0.9959dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9958815\n",
      " 5504/10044 [===============>..............] - ETA: 1:08:04 - loss: 0.0142 - crf_viterbi_accuracy: 0.9959dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99590975\n",
      " 5632/10044 [===============>..............] - ETA: 1:04:44 - loss: 0.0141 - crf_viterbi_accuracy: 0.9959dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9959273\n",
      " 5760/10044 [================>.............] - ETA: 1:01:32 - loss: 0.0141 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99595326\n",
      " 5888/10044 [================>.............] - ETA: 58:28 - loss: 0.0140 - crf_viterbi_accuracy: 0.9960  dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99596316\n",
      " 6016/10044 [================>.............] - ETA: 55:32 - loss: 0.0140 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99596226\n",
      " 6144/10044 [=================>............] - ETA: 52:44 - loss: 0.0140 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99597293\n",
      " 6272/10044 [=================>............] - ETA: 50:03 - loss: 0.0140 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99595636\n",
      " 6400/10044 [==================>...........] - ETA: 47:28 - loss: 0.0141 - crf_viterbi_accuracy: 0.9959dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99594176\n",
      " 6528/10044 [==================>...........] - ETA: 44:59 - loss: 0.0141 - crf_viterbi_accuracy: 0.9959dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99594545\n",
      " 6656/10044 [==================>...........] - ETA: 42:35 - loss: 0.0141 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9959543\n",
      " 6784/10044 [===================>..........] - ETA: 40:16 - loss: 0.0141 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99597454\n",
      " 6912/10044 [===================>..........] - ETA: 38:02 - loss: 0.0140 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9959864\n",
      " 7040/10044 [====================>.........] - ETA: 35:53 - loss: 0.0140 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99599147\n",
      " 7168/10044 [====================>.........] - ETA: 33:48 - loss: 0.0139 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99600375\n",
      " 7296/10044 [====================>.........] - ETA: 31:48 - loss: 0.0138 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99602056\n",
      " 7424/10044 [=====================>........] - ETA: 29:51 - loss: 0.0138 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9960188\n",
      " 7552/10044 [=====================>........] - ETA: 27:57 - loss: 0.0137 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9960348\n",
      " 7680/10044 [=====================>........] - ETA: 26:07 - loss: 0.0137 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9960467\n",
      " 7808/10044 [======================>.......] - ETA: 24:21 - loss: 0.0136 - crf_viterbi_accuracy: 0.9960dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9960469\n",
      " 7936/10044 [======================>.......] - ETA: 22:37 - loss: 0.0136 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99606276\n",
      " 8064/10044 [=======================>......] - ETA: 20:57 - loss: 0.0136 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9960616\n",
      " 8192/10044 [=======================>......] - ETA: 19:20 - loss: 0.0135 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99607885\n",
      " 8320/10044 [=======================>......] - ETA: 17:45 - loss: 0.0134 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9960913\n",
      " 8448/10044 [========================>.....] - ETA: 16:12 - loss: 0.0134 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99610335\n",
      " 8576/10044 [========================>.....] - ETA: 14:43 - loss: 0.0134 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961213\n",
      " 8704/10044 [========================>.....] - ETA: 13:15 - loss: 0.0133 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961225\n",
      " 8832/10044 [=========================>....] - ETA: 11:50 - loss: 0.0133 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961306\n",
      " 8960/10044 [=========================>....] - ETA: 10:27 - loss: 0.0133 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961316\n",
      " 9088/10044 [==========================>...] - ETA: 9:06 - loss: 0.0132 - crf_viterbi_accuracy: 0.9961 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961403\n",
      " 9216/10044 [==========================>...] - ETA: 7:47 - loss: 0.0132 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961402\n",
      " 9344/10044 [==========================>...] - ETA: 6:30 - loss: 0.0131 - crf_viterbi_accuracy: 0.9961dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961485\n",
      " 9472/10044 [===========================>..] - ETA: 5:15 - loss: 0.0131 - crf_viterbi_accuracy: 0.9962dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961576\n",
      " 9600/10044 [===========================>..] - ETA: 4:01 - loss: 0.0130 - crf_viterbi_accuracy: 0.9962dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961636\n",
      " 9728/10044 [============================>.] - ETA: 2:50 - loss: 0.0130 - crf_viterbi_accuracy: 0.9962dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961686\n",
      " 9856/10044 [============================>.] - ETA: 1:40 - loss: 0.0130 - crf_viterbi_accuracy: 0.9962dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961825\n",
      " 9984/10044 [============================>.] - ETA: 31s - loss: 0.0129 - crf_viterbi_accuracy: 0.9962 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961969\n",
      "dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9961853\n",
      "10044/10044 [==============================] - 10864s 1s/step - loss: 0.0129 - crf_viterbi_accuracy: 0.9962 - val_loss: 0.0167 - val_crf_viterbi_accuracy: 0.9947\n",
      "Epoch 6/6\n",
      "  128/10044 [..............................] - ETA: 4:13 - loss: 0.0053 - crf_viterbi_accuracy: 0.9982dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99820244\n",
      "  256/10044 [..............................] - ETA: 4:06 - loss: 0.0073 - crf_viterbi_accuracy: 0.9981dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99806416\n",
      "  384/10044 [>.............................] - ETA: 4:02 - loss: 0.0079 - crf_viterbi_accuracy: 0.9978dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99781066\n",
      "  512/10044 [>.............................] - ETA: 3:58 - loss: 0.0085 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9974938\n",
      "  640/10044 [>.............................] - ETA: 3:55 - loss: 0.0088 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9973728\n",
      "  768/10044 [=>............................] - ETA: 3:51 - loss: 0.0088 - crf_viterbi_accuracy: 0.9973dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99733824\n",
      "  896/10044 [=>............................] - ETA: 3:47 - loss: 0.0094 - crf_viterbi_accuracy: 0.9971dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99710613\n",
      " 1024/10044 [==>...........................] - ETA: 3:43 - loss: 0.0090 - crf_viterbi_accuracy: 0.9972dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9972086\n",
      " 1152/10044 [==>...........................] - ETA: 3:39 - loss: 0.0088 - crf_viterbi_accuracy: 0.9972dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9972346\n",
      " 1280/10044 [==>...........................] - ETA: 3:36 - loss: 0.0086 - crf_viterbi_accuracy: 0.9972dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99724835\n",
      " 1408/10044 [===>..........................] - ETA: 3:33 - loss: 0.0085 - crf_viterbi_accuracy: 0.9973dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9973351\n",
      " 1536/10044 [===>..........................] - ETA: 3:30 - loss: 0.0083 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9974189\n",
      " 1664/10044 [===>..........................] - ETA: 3:27 - loss: 0.0082 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9974366\n",
      " 1792/10044 [====>.........................] - ETA: 3:24 - loss: 0.0082 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99742216\n",
      " 1920/10044 [====>.........................] - ETA: 3:21 - loss: 0.0084 - crf_viterbi_accuracy: 0.9973dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9973451\n",
      " 2048/10044 [=====>........................] - ETA: 3:18 - loss: 0.0083 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99739003\n",
      " 2176/10044 [=====>........................] - ETA: 3:15 - loss: 0.0087 - crf_viterbi_accuracy: 0.9973dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9973321\n",
      " 2304/10044 [=====>........................] - ETA: 3:12 - loss: 0.0086 - crf_viterbi_accuracy: 0.9973dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9973458\n",
      " 2432/10044 [======>.......................] - ETA: 3:09 - loss: 0.0086 - crf_viterbi_accuracy: 0.9973dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99733996\n",
      " 2560/10044 [======>.......................] - ETA: 3:06 - loss: 0.0086 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9973589\n",
      " 2688/10044 [=======>......................] - ETA: 3:02 - loss: 0.0084 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99740565\n",
      " 2816/10044 [=======>......................] - ETA: 2:59 - loss: 0.0084 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99741673\n",
      " 2944/10044 [=======>......................] - ETA: 2:55 - loss: 0.0084 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9974088\n",
      " 3072/10044 [========>.....................] - ETA: 2:52 - loss: 0.0083 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99743325\n",
      " 3200/10044 [========>.....................] - ETA: 2:49 - loss: 0.0083 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9974502\n",
      " 3328/10044 [========>.....................] - ETA: 2:46 - loss: 0.0083 - crf_viterbi_accuracy: 0.9974dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9974366\n",
      " 3456/10044 [=========>....................] - ETA: 2:43 - loss: 0.0081 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99745727\n",
      " 3584/10044 [=========>....................] - ETA: 2:40 - loss: 0.0080 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99748886\n",
      " 3712/10044 [==========>...................] - ETA: 2:36 - loss: 0.0080 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975015\n",
      " 3840/10044 [==========>...................] - ETA: 2:33 - loss: 0.0079 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975249\n",
      " 3968/10044 [==========>...................] - ETA: 2:30 - loss: 0.0079 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99752\n",
      " 4096/10044 [===========>..................] - ETA: 2:27 - loss: 0.0079 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99751323\n",
      " 4224/10044 [===========>..................] - ETA: 2:24 - loss: 0.0079 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99751943\n",
      " 4352/10044 [===========>..................] - ETA: 2:21 - loss: 0.0078 - crf_viterbi_accuracy: 0.9975dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975395\n",
      " 4480/10044 [============>.................] - ETA: 2:18 - loss: 0.0077 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99755055\n",
      " 4608/10044 [============>.................] - ETA: 2:14 - loss: 0.0077 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99756676\n",
      " 4736/10044 [=============>................] - ETA: 2:11 - loss: 0.0076 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99758583\n",
      " 4864/10044 [=============>................] - ETA: 2:08 - loss: 0.0075 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99760205\n",
      " 4992/10044 [=============>................] - ETA: 2:05 - loss: 0.0075 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99759793\n",
      " 5120/10044 [==============>...............] - ETA: 2:02 - loss: 0.0075 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.997594\n",
      " 5248/10044 [==============>...............] - ETA: 1:58 - loss: 0.0074 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975987\n",
      " 5376/10044 [===============>..............] - ETA: 1:55 - loss: 0.0074 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99760485\n",
      " 5504/10044 [===============>..............] - ETA: 1:52 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976171\n",
      " 5632/10044 [===============>..............] - ETA: 1:49 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99761945\n",
      " 5760/10044 [================>.............] - ETA: 1:46 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99762166\n",
      " 5888/10044 [================>.............] - ETA: 1:43 - loss: 0.0074 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976057\n",
      " 6016/10044 [================>.............] - ETA: 1:40 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976052\n",
      " 6144/10044 [=================>............] - ETA: 1:36 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99759173\n",
      " 6272/10044 [=================>............] - ETA: 1:33 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975901\n",
      " 6400/10044 [==================>...........] - ETA: 1:30 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975803\n",
      " 6528/10044 [==================>...........] - ETA: 1:27 - loss: 0.0074 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975572\n",
      " 6656/10044 [==================>...........] - ETA: 1:24 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975617\n",
      " 6784/10044 [===================>..........] - ETA: 1:20 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975698\n",
      " 6912/10044 [===================>..........] - ETA: 1:17 - loss: 0.0073 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99757767\n",
      " 7040/10044 [====================>.........] - ETA: 1:14 - loss: 0.0072 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975953\n",
      " 7168/10044 [====================>.........] - ETA: 1:11 - loss: 0.0072 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99761355\n",
      " 7296/10044 [====================>.........] - ETA: 1:08 - loss: 0.0072 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975984\n",
      " 7424/10044 [=====================>........] - ETA: 1:04 - loss: 0.0072 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99759215\n",
      " 7552/10044 [=====================>........] - ETA: 1:01 - loss: 0.0072 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.997592\n",
      " 7680/10044 [=====================>........] - ETA: 58s - loss: 0.0072 - crf_viterbi_accuracy: 0.9976 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9975894\n",
      " 7808/10044 [======================>.......] - ETA: 55s - loss: 0.0072 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99759156\n",
      " 7936/10044 [======================>.......] - ETA: 52s - loss: 0.0071 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976025\n",
      " 8064/10044 [=======================>......] - ETA: 49s - loss: 0.0071 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99760765\n",
      " 8192/10044 [=======================>......] - ETA: 45s - loss: 0.0070 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99762124\n",
      " 8320/10044 [=======================>......] - ETA: 42s - loss: 0.0070 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99762386\n",
      " 8448/10044 [========================>.....] - ETA: 39s - loss: 0.0069 - crf_viterbi_accuracy: 0.9976dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976473\n",
      " 8576/10044 [========================>.....] - ETA: 36s - loss: 0.0068 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99766177\n",
      " 8704/10044 [========================>.....] - ETA: 33s - loss: 0.0068 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976555\n",
      " 8832/10044 [=========================>....] - ETA: 30s - loss: 0.0068 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99766344\n",
      " 8960/10044 [=========================>....] - ETA: 26s - loss: 0.0067 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976761\n",
      " 9088/10044 [==========================>...] - ETA: 23s - loss: 0.0067 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976903\n",
      " 9216/10044 [==========================>...] - ETA: 20s - loss: 0.0067 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976782\n",
      " 9344/10044 [==========================>...] - ETA: 17s - loss: 0.0067 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976636\n",
      " 9472/10044 [===========================>..] - ETA: 14s - loss: 0.0067 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99766994\n",
      " 9600/10044 [===========================>..] - ETA: 10s - loss: 0.0067 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976642\n",
      " 9728/10044 [============================>.] - ETA: 7s - loss: 0.0067 - crf_viterbi_accuracy: 0.9977 dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99767315\n",
      " 9856/10044 [============================>.] - ETA: 4s - loss: 0.0066 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99767643\n",
      " 9984/10044 [============================>.] - ETA: 1s - loss: 0.0066 - crf_viterbi_accuracy: 0.9977dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.9976787\n",
      "dict_keys(['batch', 'size', 'loss', 'crf_viterbi_accuracy'])\n",
      "0.99766326\n",
      "10044/10044 [==============================] - 269s 27ms/step - loss: 0.0066 - crf_viterbi_accuracy: 0.9977 - val_loss: 0.0138 - val_crf_viterbi_accuracy: 0.9953\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EMBEDDING_OUT_DIM = 200\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=n_words, output_dim=EMBEDDING_OUT_DIM, input_length=maxlen))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.3)))\n",
    "model.add(TimeDistributed(Dense(n_tags)))\n",
    "crf_layer = CRF(n_tags, sparse_target=True)\n",
    "model.add(crf_layer)\n",
    "model.compile(optimizer='adam', loss=crf_layer.loss_function, metrics=[crf_layer.accuracy])\n",
    "history = model.fit(X_train, y_train.reshape(y_train.shape[0], y_train.shape[1], 1), batch_size=128, \n",
    "                    validation_data=(X_test, y_test.reshape(y_test.shape[0], y_test.shape[1], 1)),\n",
    "                    epochs=6, verbose=1, callbacks=[logs_loss])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logs_loss.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "logs_loss.loss_plot('batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_idx2tag(y_true, y_pred):\n",
    "    y_, p_ = [], []\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "    for y_item, p_item in zip(y_true, y_pred):\n",
    "        for y,p in zip(y_item, p_item):\n",
    "            if idx2tag[y]=='TAGPAD':\n",
    "                break\n",
    "            else:\n",
    "                y_.append(idx2tag[y])\n",
    "                p_.append(idx2tag[p])\n",
    "    return np.array(y_), np.array(p_)\n",
    "\n",
    "y_pred = model.predict(X_test)   \n",
    "ytest, ptest = pred_idx2tag(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61560,), (61560,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape, ptest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score is :0.962421512628273\n"
     ]
    }
   ],
   "source": [
    "result = f1_score(ytest, ptest, average='weighted', labels=idx2tag)\n",
    "print('f1 score is :{}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.98      0.99      0.98     51215\n",
      "       I-ORG       0.81      0.81      0.81      3069\n",
      "       I-PER       0.96      0.82      0.89      3393\n",
      "      I-MISC       0.89      0.73      0.80      1370\n",
      "       I-LOC       0.90      0.87      0.88      2495\n",
      "       B-LOC       0.00      0.00      0.00         3\n",
      "      B-MISC       0.00      0.00      0.00         7\n",
      "       B-ORG       0.00      0.00      0.00         8\n",
      "      TAGPAD       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.96     61560\n",
      "   macro avg       0.50      0.47      0.49     61560\n",
      "weighted avg       0.96      0.96      0.96     61560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = classification_report(ytest, ptest, labels=idx2tag)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Bidirectional LSTM-CRF model, I used keras to apply. The f1 score was 0.962, still slightly lower than the CRF model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "I will choose the Conditional Random Fields (CRF) model. It has the best performance since it has the largest F1 score of 0.9796403640122624."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
