{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SI 671 Homework 2\n",
    "uniqname: Yipeng Chen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignore warnings for training.\n",
    "\n",
    "### 1. Data reading\n",
    "I don't think I'm very care about how many documentations and how many sentences they have. Just get the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    res = []\n",
    "    doc_num = 0\n",
    "    with open(path, 'r') as fr:\n",
    "        for line in fr.readlines():\n",
    "            if line == '-DOCSTART- -X- O O\\n':\n",
    "                doc_num += 1\n",
    "            elif line != '\\n' and line != '-DOCSTART- -X- O O\\n':\n",
    "                res.append([doc_num] + line.split())\n",
    "        df = pd.DataFrame(res, columns=['doc_num', 'word', 'pos', 'chunking', 'tag'])\n",
    "\n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "path = './DataNer.txt'\n",
    "df = read_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunking</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>further</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>scientific</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_num        word  pos chunking tag\n",
       "0        1          He  PRP     I-NP   O\n",
       "1        1        said  VBD     I-VP   O\n",
       "2        1     further   JJ     I-NP   O\n",
       "3        1  scientific   JJ     I-NP   O\n",
       "4        1       study   NN     I-NP   O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunking</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207270</td>\n",
       "      <td>207270</td>\n",
       "      <td>207270</td>\n",
       "      <td>207270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>23825</td>\n",
       "      <td>45</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>.</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>7486</td>\n",
       "      <td>35159</td>\n",
       "      <td>122477</td>\n",
       "      <td>172494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word     pos chunking     tag\n",
       "count   207270  207270   207270  207270\n",
       "unique   23825      45       17       8\n",
       "top          .     NNP     I-NP       O\n",
       "freq      7486   35159   122477  172494"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 1:].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.doc_num.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207270, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do a little bit data interpretations here. \n",
    "1. We can see that we have 8 unique values for label and 'O' has the most of the value.\n",
    "2. We have 46 different unique values of pos and 17 unique values of chunking_tag\n",
    "3. We have 207270 rows and 23825 unique word.\n",
    "4. We have 960 different docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data handling\n",
    "1. one hot encoding\n",
    "2. prepare train and test data\n",
    "3. prepare class list without 'O' tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "df_dict = df[['word', 'pos', 'chunking']].to_dict(\"record\")\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vector = DictVectorizer(sparse=True)\n",
    "X = vector.fit_transform(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['tag'].values, test_size = 0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class list without 'O'\n",
    "class_list = df.tag.unique().tolist()[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explaination\n",
    "1. For most of the data, what we want is a sparse vector so that the training would be faster, so I use DictVectorizer to on onehot encoding.\n",
    "2. Then we do the train_test split in order to do training and inference.\n",
    "3. Also, we need to filter 'O' for classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite.metrics import flat_f1_score\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9482309264147721\n",
      "best iter:  1000\n",
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       I-ORG       0.86      0.60      0.71      3078\n",
      "       I-PER       0.73      0.94      0.82      3498\n",
      "      I-MISC       0.88      0.57      0.69      1381\n",
      "       I-LOC       0.87      0.73      0.80      2497\n",
      "       B-LOC       1.00      0.60      0.75         5\n",
      "      B-MISC       0.00      0.00      0.00        12\n",
      "       B-ORG       0.25      1.00      0.40         7\n",
      "\n",
      "   micro avg       0.80      0.74      0.77     10478\n",
      "   macro avg       0.66      0.63      0.60     10478\n",
      "weighted avg       0.82      0.74      0.76     10478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_list = [1000, 2000]\n",
    "best_score = 0\n",
    "best_iter = 0\n",
    "best_pred = []\n",
    "for i in alpha_list:\n",
    "    model = linear_model.SGDClassifier(max_iter=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    tmp_score = f1_score(y_test, y_pred, average='weighted')\n",
    "    if tmp_score > best_score:\n",
    "        best_score = tmp_score\n",
    "        best_pred = y_pred\n",
    "        best_iter = i\n",
    "        \n",
    "result = classification_report(y_pred=best_pred, y_true=y_test, labels=class_list)\n",
    "print('f1 score: ', best_score)\n",
    "print('best iter: ', best_iter)\n",
    "print('report: \\n', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination\n",
    "1. We apply SGD classifier with (1000, 2000) max iteration.\n",
    "2. We find that 1000 is the better than 2000\n",
    "3. f1 score is 0.94, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9537495610142331\n",
      "best alpha:  0.1\n",
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       I-ORG       0.86      0.70      0.77      3078\n",
      "       I-PER       0.73      0.96      0.83      3498\n",
      "      I-MISC       0.65      0.78      0.71      1381\n",
      "       I-LOC       0.86      0.81      0.83      2497\n",
      "       B-LOC       0.00      0.00      0.00         5\n",
      "      B-MISC       0.00      0.00      0.00        12\n",
      "       B-ORG       0.00      0.00      0.00         7\n",
      "\n",
      "   micro avg       0.78      0.82      0.80     10478\n",
      "   macro avg       0.44      0.46      0.45     10478\n",
      "weighted avg       0.79      0.82      0.80     10478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_list = [0.1, 1, 10]\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "best_pred = []\n",
    "for i in alpha_list:\n",
    "    model = MultinomialNB(alpha=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    tmp_score = f1_score(y_test, y_pred, average='weighted')\n",
    "    if tmp_score > best_score:\n",
    "        best_score = tmp_score\n",
    "        best_pred = y_pred\n",
    "        best_alpha = i\n",
    "        \n",
    "result = classification_report(y_pred=best_pred, y_true=y_test, labels=class_list)\n",
    "print('f1 score: ', best_score)\n",
    "print('best alpha: ', best_alpha)\n",
    "print('report: \\n', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination\n",
    "1. We apply MultinomialNB classifier with (0.1, 1, 10) alpha.\n",
    "2. We find that 0.1 is the better than others\n",
    "3. f1 score is 0.953, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9428234857389134\n",
      "best alpha:  1e-06\n",
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       I-ORG       0.96      0.47      0.63      3078\n",
      "       I-PER       0.99      0.65      0.78      3498\n",
      "      I-MISC       0.83      0.78      0.81      1381\n",
      "       I-LOC       0.50      0.95      0.65      2497\n",
      "       B-LOC       0.80      0.80      0.80         5\n",
      "      B-MISC       0.00      0.00      0.00        12\n",
      "       B-ORG       0.05      1.00      0.09         7\n",
      "\n",
      "   micro avg       0.72      0.69      0.70     10478\n",
      "   macro avg       0.59      0.66      0.54     10478\n",
      "weighted avg       0.84      0.69      0.71     10478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_list = [1e-6, 1e-5, 1e-4]\n",
    "best_score = 0\n",
    "best_alpha = 0\n",
    "best_pred = []\n",
    "for i in alpha_list:\n",
    "    model = linear_model.Perceptron(alpha=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    tmp_score = f1_score(y_test, y_pred, average='weighted')\n",
    "    if tmp_score > best_score:\n",
    "        best_score = tmp_score\n",
    "        best_pred = y_pred\n",
    "        best_alpha = i\n",
    "        \n",
    "result = classification_report(y_pred=best_pred, y_true=y_test, labels=class_list)\n",
    "print('f1 score: ', best_score)\n",
    "print('best alpha: ', best_alpha)\n",
    "print('report: \\n', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination\n",
    "1. We apply MultinomialNB classifier with (1e-6, 1e-5, 1e-4) alpha.\n",
    "2. We find that 1e-6 is the better than others\n",
    "3. f1 score is 0.94, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Random Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>chunking</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>He</td>\n",
       "      <td>PRP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>I-VP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>further</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>scientific</td>\n",
       "      <td>JJ</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>study</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_num        word  pos chunking tag\n",
       "0        1          He  PRP     I-NP   O\n",
       "1        1        said  VBD     I-VP   O\n",
       "2        1     further   JJ     I-NP   O\n",
       "3        1  scientific   JJ     I-NP   O\n",
       "4        1       study   NN     I-NP   O"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_doc = df.groupby('doc_num').apply(lambda s: [(a, b, c) for a, b, c in zip(s.word.values.tolist(), \n",
    "                                                   s.pos.values.tolist(), \n",
    "                                                   s.tag.values.tolist())])\n",
    "docs = [s for s in group_doc]\n",
    "\n",
    "X = [sent2features(s) for s in docs]\n",
    "y = [sent2labels(s) for s in docs]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9677881176213229\n",
      "best algorithm:  lbfgs\n",
      "report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       I-ORG       0.84      0.77      0.81      3079\n",
      "       I-PER       0.87      0.92      0.89      3302\n",
      "      I-MISC       0.88      0.76      0.82      1366\n",
      "       I-LOC       0.86      0.87      0.87      2516\n",
      "       B-LOC       0.00      0.00      0.00        10\n",
      "      B-MISC       1.00      0.20      0.33        10\n",
      "       B-ORG       0.00      0.00      0.00         0\n",
      "\n",
      "   micro avg       0.86      0.84      0.85     10283\n",
      "   macro avg       0.64      0.50      0.53     10283\n",
      "weighted avg       0.86      0.84      0.85     10283\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alpha_list = ['lbfgs', 'l2sgd']\n",
    "best_score = 0\n",
    "best_alpha = ''\n",
    "best_pred = []\n",
    "for i in alpha_list:\n",
    "    model = CRF(algorithm=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    tmp_score = flat_f1_score(y_test, y_pred, average='weighted')\n",
    "    if tmp_score > best_score:\n",
    "        best_score = tmp_score\n",
    "        best_pred = y_pred\n",
    "        best_alpha = i\n",
    "        \n",
    "result = flat_classification_report(y_pred=best_pred, y_true=y_test, labels=class_list)\n",
    "print('f1 score: ', best_score)\n",
    "print('best algorithm: ', best_alpha)\n",
    "print('report: \\n', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here we regard documents as a seperator.\n",
    "2. We group by the docs and then generate training and test data set. (With use of word2features and so on)\n",
    "3. Then we apply CRF model to train in inference the model.\n",
    "4. f1 score is 0.967, which is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM-CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23826"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(set(df[\"word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "n_words = len(words); n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(set(df[\"tag\"].values))\n",
    "n_tags = len(tags); n_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentence \n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"word\"].values.tolist(),\n",
    "                                                           s[\"pos\"].values.tolist(),\n",
    "                                                           s[\"tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"doc_num\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "getter = SentenceGetter(df)\n",
    "sent = getter.get_next()\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(s) for s in sentences])\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words-1)\n",
    "\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags) for i in y]\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chenyipeng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/chenyipeng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/chenyipeng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/chenyipeng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/chenyipeng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/chenyipeng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=n_words + 1, output_dim=20,\n",
    "                  input_length=max_len, mask_zero=True)(input)  # 20-dim embedding\n",
    "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
    "                           recurrent_dropout=0.1))(model)  # variational biLSTM\n",
    "model = TimeDistributed(Dense(50, activation=\"relu\"))(model)  # a dense layer as suggested by neuralNer\n",
    "crf = CRF(n_tags)  # CRF layer\n",
    "out = crf(model)  # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chenyipeng/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=crf.loss_function, metrics=[crf.accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1335)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1335, 20)          476540    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1335, 100)         28400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 1335, 50)          5050      \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, 1335, 8)           488       \n",
      "=================================================================\n",
      "Total params: 510,478\n",
      "Trainable params: 510,478\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/chenyipeng/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 604 samples, validate on 68 samples\n",
      "Epoch 1/5\n",
      "604/604 [==============================] - 36s 59ms/step - loss: 0.9533 - crf_viterbi_accuracy: 0.6655 - val_loss: 0.1435 - val_crf_viterbi_accuracy: 0.9753\n",
      "Epoch 2/5\n",
      "604/604 [==============================] - 34s 56ms/step - loss: 0.1496 - crf_viterbi_accuracy: 0.9722 - val_loss: 0.1258 - val_crf_viterbi_accuracy: 0.9753\n",
      "Epoch 3/5\n",
      "604/604 [==============================] - 35s 59ms/step - loss: 0.1357 - crf_viterbi_accuracy: 0.9721 - val_loss: 0.1054 - val_crf_viterbi_accuracy: 0.9753\n",
      "Epoch 4/5\n",
      "604/604 [==============================] - 33s 55ms/step - loss: 0.1146 - crf_viterbi_accuracy: 0.9724 - val_loss: 0.1002 - val_crf_viterbi_accuracy: 0.9753\n",
      "Epoch 5/5\n",
      "604/604 [==============================] - 34s 56ms/step - loss: 0.1064 - crf_viterbi_accuracy: 0.9724 - val_loss: 0.0990 - val_crf_viterbi_accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_tr, np.array(y_tr), batch_size=32, epochs=5,\n",
    "                    validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.invert_xaxis()\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('acc')\n",
    "plt.plot(hist[\"loss\"],hist[\"crf_viterbi_accuracy\"],)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'I-LOC',\n",
       " 1: 'I-ORG',\n",
       " 2: 'B-LOC',\n",
       " 3: 'B-MISC',\n",
       " 4: 'I-MISC',\n",
       " 5: 'B-ORG',\n",
       " 6: 'I-PER',\n",
       " 7: 'O'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 3s 12ms/step\n",
      "F1-score: 96.0%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.00      0.00      0.00        10\n",
      "      B-MISC       0.00      0.00      0.00        10\n",
      "       I-LOC       0.00      0.00      0.00      2516\n",
      "      I-MISC       0.00      0.00      0.00      1366\n",
      "       I-ORG       0.00      0.00      0.00      3079\n",
      "       I-PER       0.00      0.00      0.00      3302\n",
      "           O       0.97      1.00      0.99    374197\n",
      "\n",
      "    accuracy                           0.97    384480\n",
      "   macro avg       0.14      0.14      0.14    384480\n",
      "weighted avg       0.95      0.97      0.96    384480\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "test_pred = model.predict(X_te, verbose=1)\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "\n",
    "def pred2label(pred):\n",
    "    out = []\n",
    "    for pred_i in pred:\n",
    "        out_i = []\n",
    "        for p in pred_i:\n",
    "            p_i = np.argmax(p)\n",
    "            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n",
    "        out.append(out_i)\n",
    "    return out\n",
    "    \n",
    "pred_labels = pred2label(test_pred)\n",
    "test_labels = pred2label(y_te)\n",
    "pred_labels = sum(pred_labels, [])\n",
    "test_labels = sum(test_labels, [])\n",
    "\n",
    "print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels,average='weighted')))\n",
    "print(classification_report(test_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Here we regard documents as a seperator.\n",
    "2. We group by the docs and then generate training and test data set. (With use of SentenceGetter and so on). Here my doc means sentence instead.\n",
    "3. Then we use keras to apply Bidirectional LSTM-CRF model to train in inference the model.\n",
    "4. f1 score is 0.96, which is good. But notice that for classification report, only 'O' has big acc and recall, which is bad. There may be some overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
